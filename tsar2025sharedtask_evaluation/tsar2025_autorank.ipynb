{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b3189-2604-4cbb-bb45-e37b56c3dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc799433-a198-453c-bc49-95bb86acd40d",
   "metadata": {},
   "source": [
    "## 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e35db-6c6e-4871-a042-77ab88848447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = \"results.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"Tabelle1\")\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfa9b1-77ed-406e-a753-9de341263a83",
   "metadata": {},
   "source": [
    "## 2. Filter valid runs\n",
    "We only keep runs with the full 200 test instances.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170c670-6db4-4b38-bf3f-55b7bc1328ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"num_instances\"] == 200].copy()\n",
    "print(f\"Valid runs after filtering: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae395a1f-9e69-4f4d-a3c0-72b6caf23353",
   "metadata": {},
   "source": [
    "## 3. Define helper functions\n",
    "We implement:\n",
    "- **Median–interpercentile scaling (10–90%)**  \n",
    "- **AUTORANK computation with custom weights**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564d3c4-40cc-478f-a9bc-a71d80a8eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def median_interpercentile_scale(values, low=10, high=90):\n",
    "    values = np.array(values)\n",
    "    median = np.median(values)\n",
    "    p_low, p_high = np.percentile(values, [low, high])\n",
    "    denom = p_high - p_low if p_high > p_low else 1.0\n",
    "    return (values - median) / denom\n",
    "\n",
    "# AUTORANK with custom weights\n",
    "def compute_autorank_weighted(data, weights, directions, low=10, high=90):\n",
    "    # 1. Median–interpercentile scaling\n",
    "    scaled = data.apply(lambda col: median_interpercentile_scale(col, low, high))\n",
    "    \n",
    "    # 2. Flip orientation if lower=better\n",
    "    for col, up in zip(scaled.columns, directions):\n",
    "        if not up:\n",
    "            scaled[col] = -scaled[col]\n",
    "    \n",
    "    # 3. Weighted average\n",
    "    weights = np.array(weights, dtype=float)\n",
    "    weights = weights / weights.sum()\n",
    "    avg_score = np.dot(scaled.values, weights)\n",
    "    \n",
    "    # 4. Rescale to [1, N]\n",
    "    N = len(avg_score)\n",
    "    min_val, max_val = avg_score.min(), avg_score.max()\n",
    "    rescaled = 1 + (avg_score - min_val) * (N - 1) / (max_val - min_val) if max_val > min_val else np.ones_like(avg_score)\n",
    "    \n",
    "    # 5. Final AUTORANK mapping (1=best, N=worst)\n",
    "    min_val, max_val = rescaled.min(), rescaled.max()\n",
    "    autorank = 1 + (max_val - rescaled) * (N - 1) / (max_val - min_val) if max_val > min_val else np.ones_like(rescaled)\n",
    "    \n",
    "    return avg_score, rescaled, autorank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5dcb56-8238-429f-88f6-98a01409ed82",
   "metadata": {},
   "source": [
    "## 4. Define metrics and weights\n",
    "We evaluate with 3 metrics:\n",
    "- **RMSE** (lower=better)  \n",
    "- **MeaningBERT original–output** (higher=better)  \n",
    "- **MeaningBERT reference–output** (higher=better)  \n",
    "\n",
    "Weights:  \n",
    "- RMSE = 0.50  \n",
    "- MB-orig = 0.167  \n",
    "- MB-ref = 0.333  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d5e37-c6fd-4ac3-84f7-e4ab7a71b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"rmse\", \"meaningbert-orig\", \"meaningbert-ref\"]\n",
    "weights = [0.5, 0.167, 0.333]\n",
    "directions = [False, True, True]  # RMSE lower=better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e87da-cd39-4fe1-b72d-c83428b0cb90",
   "metadata": {},
   "source": [
    "## 5. Compute AUTORANK scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989be628-3ca4-4424-a8ea-46c7a8b5040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = df[metrics]\n",
    "avg_score, rescaled, autorank = compute_autorank_weighted(subdf, weights, directions)\n",
    "\n",
    "df[\"AvgScore\"] = avg_score\n",
    "df[\"Rescaled\"] = rescaled\n",
    "df[\"AUTORANK\"] = autorank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64480e85-994a-4c20-b530-c42026da9f30",
   "metadata": {},
   "source": [
    "## 6. Rankings\n",
    "We generate:\n",
    "1. **All runs ranking**  \n",
    "2. **Best run per team ranking**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d42469-2c5a-46d7-bff4-8550575ec8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All runs\n",
    "all_runs = df.sort_values(\"AUTORANK\")\n",
    "\n",
    "# Best run per team\n",
    "best_runs = df.loc[df.groupby(\"teamname\")[\"AUTORANK\"].idxmin()]\n",
    "best_runs = best_runs.sort_values(\"AUTORANK\")\n",
    "\n",
    "all_runs.head(), best_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb8387-8409-4df3-b7bc-a2c2deb07cf1",
   "metadata": {},
   "source": [
    "## 7. Export LaTeX tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe2b39-5a21-468c-902a-ca77e4fdde23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_latex_table(data, caption, label):\n",
    "    cols = [\"teamname\", \"modelname\"] + metrics + [\"AvgScore\", \"AUTORANK\"]\n",
    "    table = data[cols].copy()\n",
    "    table[\"AvgScore\"] = table[\"AvgScore\"].round(3)\n",
    "    table[\"AUTORANK\"] = table[\"AUTORANK\"].round(2)\n",
    "    return table.to_latex(\n",
    "        float_format=\"%.3f\",\n",
    "        index=False,\n",
    "        escape=False,\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        column_format=\"llccccc\",\n",
    "        bold_rows=False\n",
    "    )\n",
    "\n",
    "latex_all = to_latex_table(all_runs, \"AUTORANK results for all submitted runs (custom weighting).\", \"tab:autorank_all\")\n",
    "latex_best = to_latex_table(best_runs, \"AUTORANK results using the best run per team (custom weighting).\", \"tab:autorank_best\")\n",
    "\n",
    "print(latex_all)\n",
    "print(latex_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
